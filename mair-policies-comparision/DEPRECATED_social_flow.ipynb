{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data.utils import process_all_documents\n",
    "from load_data import load_dataframe, process_text\n",
    "from plots import plot_counter_lemmas\n",
    "\n",
    "from load_data import load_processed_data\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle \n",
    "import time\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import ast\n",
    "import pyLDAvis\n",
    "import glob \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_names= {'Summary': ['Summary'],\n",
    " \"National schemes\": ['Description of national schemes providing minimum income support'],\n",
    " 'Links with labour market activation': ['Links with labour market activation'],\n",
    " \"Links to social services\": ['Links to social services and integrated provision of targeted social services'],\n",
    " 'Governance mechanisms': ['Governance mechanisms'],\n",
    " 'Impact of minimum income schemes': ['Impact of minimum income schemes', 'Impact of MI schemes'],\n",
    " 'Sources': ['Sources']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_all_documents('social_reports/', paragraphs_names, 'social_reports/txt_files/', 'Sources')\n",
    "df.to_csv('documents.csv')\n",
    "dft = load_dataframe('documents.csv')\n",
    "processed_df = process_text(dft)\n",
    "\n",
    "common_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = load_processed_data(data_path, stop_words=STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'Summary'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 5\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'National schemes'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 5\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links with labour market activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'Links with labour market activation'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 10\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links to social services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'Links to social services'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 7\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Governance mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'Governance mechanisms'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 6\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of minimum income schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_name = 'Impact of minimum income schemes'\n",
    "filter_dict = {'paragraph': par_name}\n",
    "plot_counter_lemmas(processed_df, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words_filtered = 6\n",
    "filtered_lemmas = processed_df.loc[(processed_df[list(filter_dict)] == pd.Series(filter_dict)).all(axis=1)][\"lemmas\"]\n",
    "counter = Counter(filtered_lemmas.sum()).most_common(number_words_filtered)\n",
    "common_words[par_name] = [word for word, cnt in counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_numbers_range = (3, 10)\n",
    "alpha = 100\n",
    "results_folder = \"./social_results/lda/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pipeline(par, alpha):\n",
    "    print(f\"Pipeline for {par} with alpha={alpha} started\")\n",
    "    filter_dict = {'paragraph': par}\n",
    "    filter_dict = {'paragraph': par}\n",
    "    (filtered_lemmas, models, encoded_docs, lemmas_dictionary, cvs) = check_coherence_for_topics_num(\n",
    "        processed_df,\n",
    "        filter_dict,\n",
    "        common_words[par],\n",
    "        topic_numbers_range,\n",
    "        alpha\n",
    "    )\n",
    "    num_topics = find_best_topics_num(cvs, topic_numbers_range)\n",
    "    print(f\"Best number of topics found: {num_topics}\")\n",
    "    lda_model = find_best_model(encoded_docs, lemmas_dictionary, cvs, topic_numbers_range, random_state=42, alpha=alpha)\n",
    "    encoded_docs.to_csv(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_encoded_docs.csv\")\n",
    "    lemmas_dictionary.save(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_dictionary.dict\")\n",
    "    lda_model.save(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_lda_model.model\")\n",
    "    print(\"Best model found and saved\")\n",
    "    topic_words = _topics_df(lda_model, filtered_lemmas, 30)\n",
    "    modeling_results, topic_probs = get_topic_probs(processed_df, filter_dict, lda_model, num_topics, encoded_docs)\n",
    "    topics_by_country = topic_probs_by_column_binded(modeling_results, num_topics, column='country')\n",
    "    topics_by_country.to_csv(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_probs.csv\")\n",
    "    tsne_mapping = tsne_dim_reduction(topics_by_country, num_topics * 3, perplexity=10)\n",
    "    umap_mapping = umap_dim_reduction(topics_by_country, num_topics * 3, random_state=42)\n",
    "    mappings = tsne_mapping.join(umap_mapping)\n",
    "    mappings.to_csv(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_mapping.csv\")\n",
    "    topic_words.to_csv(str(alpha) + \"_\" + par.replace(\" \", \"_\") +\"_topic_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in paragraphs_names.keys():\n",
    "        if key == \"Sources\":\n",
    "                continue\n",
    "        do_pipeline(key, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gpt3_model = \"text-davinci-002\"\n",
    "temperature = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files_list = glob.glob(\"./social_results/lda/*probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_file in tqdm(result_files_list): \n",
    "    topic_df = pd.read_csv(result_file)\n",
    "    topic_keywords = pd.read_csv(result_file.replace(\"probs\", \"topic_words\"))\n",
    "    colnames = topic_df.columns.to_list()\n",
    "    topic_colnames = colnames[1:-4]\n",
    "    n_topics = len(topic_colnames)\n",
    "    for i, colname in enumerate(topic_colnames[:n_topics]):\n",
    "        time.sleep(1)\n",
    "        n_keywords = np.min([np.sum(topic_keywords[\"topic_id\"] == int(colname)), 25])\n",
    "        keywords = topic_keywords[topic_keywords[\"topic_id\"] == int(colname)].word.to_list()[:n_keywords]\n",
    "        weights = topic_keywords[topic_keywords[\"topic_id\"] == int(colname)].importance.to_list()[:n_keywords]\n",
    "        prompt = _generate_prompt(keywords, weights) \n",
    "        title = _generate_title(prompt, gpt3_model, temperature)\n",
    "        topic_colnames[i] = title\n",
    "    colnames[1:-4] = topic_colnames\n",
    "    topic_df.columns = colnames\n",
    "    topic_df.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_file in tqdm(result_files_list): \n",
    "    lda_model = LdaModel.load(result_file.replace(\"_probs.csv\", \"_lda_model.model\"))\n",
    "    encoded_docs = pd.read_csv(result_file.replace(\"_probs.csv\", \"_encoded_docs.csv\")).set_index(\"Unnamed: 0\")\n",
    "    encoded_docs.index.name = None\n",
    "    encoded_docs = encoded_docs.lemmas\n",
    "    encoded_docs = encoded_docs.apply(lambda x: ast.literal_eval(x))\n",
    "    lemmas_dictionary = Dictionary.load(result_file.replace(\"_probs.csv\", \"_dictionary.dict\"))\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, encoded_docs, lemmas_dictionary)\n",
    "    vis_html_string = pyLDAvis.prepared_data_to_html(vis)\n",
    "    with open(result_file.replace(\"_probs.csv\", \"_vis.txt\"), \"w\") as text_file:\n",
    "        text_file.write(vis_html_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f2d31f3cfa242181f85bb58fcdf4b9b5b4fad4a1c371137165c825fb1a7558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
